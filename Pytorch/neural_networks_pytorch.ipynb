{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural_networks_pytorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Wd-2-D-aHHT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "48c3b63b-3a17-4df0-e346-4d0637250a17"
      },
      "source": [
        "!pip3 install torch torchvision"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXrdEO7LaPet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1RokHQVai2W",
        "colab_type": "text"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aat9UymGaVYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = torch.tensor(([2, 9], [1, 5], [3, 6]), dtype=torch.float) # 3 X 2 tensor\n",
        "y = torch.tensor(([92], [100], [89]), dtype=torch.float) # 3 X 1 tensor\n",
        "xPredicted = torch.tensor(([4, 8]), dtype=torch.float) # 1 X 2 tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPhuLDR9aaYI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "03b41ea8-887f-4ae0-802e-029d69f2b6f8"
      },
      "source": [
        "print(X.size())\n",
        "print(y.size())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 2])\n",
            "torch.Size([3, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwZgA8Mbb3Jf",
        "colab_type": "text"
      },
      "source": [
        "### Scaling\n",
        "\n",
        "对数据做归一化的操作"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vCE3v5vanCd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "fa19c03a-8f1e-467a-fc79-62df936ebff9"
      },
      "source": [
        "# scale units\n",
        "X_max, _ = torch.max(X, 0)\n",
        "xPredicted_max, _ = torch.max(xPredicted, 0)\n",
        "\n",
        "X = torch.div(X, X_max)\n",
        "xPredicted = torch.div(xPredicted, xPredicted_max)\n",
        "y = y / 100  # max test score is 100\n",
        "print(xPredicted)\n",
        "print(X)\n",
        "print(y)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.5000, 1.0000])\n",
            "tensor([[0.6667, 1.0000],\n",
            "        [0.3333, 0.5556],\n",
            "        [1.0000, 0.6667]])\n",
            "tensor([[0.9200],\n",
            "        [1.0000],\n",
            "        [0.8900]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95pg3ILzcmDz",
        "colab_type": "text"
      },
      "source": [
        "### Model\n",
        "\n",
        "建立网络模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Acz1LRCrcKcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Neural_Network(nn.Module):\n",
        "    def __init__(self, ):\n",
        "        super(Neural_Network, self).__init__()\n",
        "        # parameters\n",
        "        # TODO: parameters can be parameterized instead of declaring them here\n",
        "        self.inputSize = 2\n",
        "        self.outputSize = 1\n",
        "        self.hiddenSize = 3\n",
        "        \n",
        "        # weights\n",
        "        self.W1 = torch.randn(self.inputSize, self.hiddenSize) # 2 X 3 tensor\n",
        "        self.W2 = torch.randn(self.hiddenSize, self.outputSize) # 3 X 1 tensor\n",
        "\n",
        "        \n",
        "    def forward(self, X):\n",
        "        self.z = torch.matmul(X, self.W1) # 3 X 3 \".dot\" does not broadcast in PyTorch\n",
        "        self.z2 = self.sigmoid(self.z) # activation function\n",
        "        self.z3 = torch.matmul(self.z2, self.W2)\n",
        "        o = self.sigmoid(self.z3) # final activation function\n",
        "        return o\n",
        "        \n",
        "    def sigmoid(self, s):\n",
        "        return 1 / (1 + torch.exp(-s))\n",
        "    \n",
        "    def sigmoidPrime(self, s):\n",
        "        # derivative of sigmoid\n",
        "        return s * (1 - s)\n",
        "    \n",
        "    def backward(self, X, y, o):\n",
        "        self.o_error = y - o # error in output\n",
        "        self.o_delta = self.o_error * self.sigmoidPrime(o) # derivative of sig to error\n",
        "        self.z2_error = torch.matmul(self.o_delta, torch.t(self.W2))\n",
        "        self.z2_delta = self.z2_error * self.sigmoidPrime(self.z2)\n",
        "        self.W1 += torch.matmul(torch.t(X), self.z2_delta)\n",
        "        self.W2 += torch.matmul(torch.t(self.z2), self.o_delta)\n",
        "        \n",
        "    def train(self, X, y):\n",
        "        # forward + backward pass for training\n",
        "        o = self.forward(X)\n",
        "        self.backward(X, y, o)\n",
        "        \n",
        "    def saveWeights(self, model):\n",
        "        # we will use the PyTorch internal storage functions\n",
        "        torch.save(model, \"NN\")\n",
        "        # you can reload model with all the weights and so forth with:\n",
        "        # torch.load(\"NN\")\n",
        "        \n",
        "    def predict(self):\n",
        "        print (\"Predicted data based on trained weights: \")\n",
        "        print (\"Input (scaled): \\n\" + str(xPredicted))\n",
        "        print (\"Output: \\n\" + str(self.forward(xPredicted)))\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTx95FRYdNG5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16934
        },
        "outputId": "67ee2308-37f8-41f1-e203-017b0eadc05d"
      },
      "source": [
        "NN = Neural_Network()\n",
        "for i in range(1000):  # trains the NN 1,000 times\n",
        "    print (\"#\" + str(i) + \" Loss: \" + str(torch.mean((y - NN(X))**2).detach().item()))  # mean sum squared loss\n",
        "    NN.train(X, y)\n",
        "NN.saveWeights(NN)\n",
        "NN.predict()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#0 Loss: 0.06439349055290222\n",
            "#1 Loss: 0.04925112798810005\n",
            "#2 Loss: 0.039051517844200134\n",
            "#3 Loss: 0.03190300241112709\n",
            "#4 Loss: 0.026714110746979713\n",
            "#5 Loss: 0.022832700982689857\n",
            "#6 Loss: 0.019854051992297173\n",
            "#7 Loss: 0.017517797648906708\n",
            "#8 Loss: 0.015650788322091103\n",
            "#9 Loss: 0.014134515076875687\n",
            "#10 Loss: 0.01288565993309021\n",
            "#11 Loss: 0.011844388209283352\n",
            "#12 Loss: 0.010966721922159195\n",
            "#13 Loss: 0.010219814255833626\n",
            "#14 Loss: 0.009578733704984188\n",
            "#15 Loss: 0.009024213999509811\n",
            "#16 Loss: 0.008541240356862545\n",
            "#17 Loss: 0.008117935620248318\n",
            "#18 Loss: 0.007744795177131891\n",
            "#19 Loss: 0.007414163555949926\n",
            "#20 Loss: 0.00711977481842041\n",
            "#21 Loss: 0.006856521591544151\n",
            "#22 Loss: 0.006620144471526146\n",
            "#23 Loss: 0.006407087203115225\n",
            "#24 Loss: 0.006214401219040155\n",
            "#25 Loss: 0.006039546802639961\n",
            "#26 Loss: 0.005880414042621851\n",
            "#27 Loss: 0.005735166370868683\n",
            "#28 Loss: 0.0056022400967776775\n",
            "#29 Loss: 0.005480291787534952\n",
            "#30 Loss: 0.005368145648390055\n",
            "#31 Loss: 0.005264792125672102\n",
            "#32 Loss: 0.005169341806322336\n",
            "#33 Loss: 0.0050810109823942184\n",
            "#34 Loss: 0.004999120254069567\n",
            "#35 Loss: 0.004923059139400721\n",
            "#36 Loss: 0.004852307494729757\n",
            "#37 Loss: 0.004786379169672728\n",
            "#38 Loss: 0.0047248490154743195\n",
            "#39 Loss: 0.0046673426404595375\n",
            "#40 Loss: 0.004613528493791819\n",
            "#41 Loss: 0.004563086666166782\n",
            "#42 Loss: 0.004515770357102156\n",
            "#43 Loss: 0.004471309948712587\n",
            "#44 Loss: 0.004429491236805916\n",
            "#45 Loss: 0.004390112590044737\n",
            "#46 Loss: 0.004352992866188288\n",
            "#47 Loss: 0.004317965824157\n",
            "#48 Loss: 0.004284881055355072\n",
            "#49 Loss: 0.0042535993270576\n",
            "#50 Loss: 0.004223996307700872\n",
            "#51 Loss: 0.00419594906270504\n",
            "#52 Loss: 0.004169362131506205\n",
            "#53 Loss: 0.00414413632825017\n",
            "#54 Loss: 0.004120185039937496\n",
            "#55 Loss: 0.004097421187907457\n",
            "#56 Loss: 0.004075761418789625\n",
            "#57 Loss: 0.004055163823068142\n",
            "#58 Loss: 0.004035526886582375\n",
            "#59 Loss: 0.004016820807009935\n",
            "#60 Loss: 0.003998973872512579\n",
            "#61 Loss: 0.003981947898864746\n",
            "#62 Loss: 0.003965675365179777\n",
            "#63 Loss: 0.003950131591409445\n",
            "#64 Loss: 0.0039352732710540295\n",
            "#65 Loss: 0.0039210449904203415\n",
            "#66 Loss: 0.003907429054379463\n",
            "#67 Loss: 0.0038943837862461805\n",
            "#68 Loss: 0.0038818849716335535\n",
            "#69 Loss: 0.0038698993157595396\n",
            "#70 Loss: 0.003858393058180809\n",
            "#71 Loss: 0.003847347805276513\n",
            "#72 Loss: 0.0038367409724742174\n",
            "#73 Loss: 0.0038265467155724764\n",
            "#74 Loss: 0.0038167478051036596\n",
            "#75 Loss: 0.003807320259511471\n",
            "#76 Loss: 0.003798246383666992\n",
            "#77 Loss: 0.0037895087152719498\n",
            "#78 Loss: 0.003781098872423172\n",
            "#79 Loss: 0.0037729935720562935\n",
            "#80 Loss: 0.0037651683669537306\n",
            "#81 Loss: 0.0037576258182525635\n",
            "#82 Loss: 0.003750347765162587\n",
            "#83 Loss: 0.00374332326464355\n",
            "#84 Loss: 0.0037365350872278214\n",
            "#85 Loss: 0.0037299806717783213\n",
            "#86 Loss: 0.003723639063537121\n",
            "#87 Loss: 0.003717513754963875\n",
            "#88 Loss: 0.0037115756422281265\n",
            "#89 Loss: 0.0037058412563055754\n",
            "#90 Loss: 0.003700281260535121\n",
            "#91 Loss: 0.0036948993802070618\n",
            "#92 Loss: 0.003689681878313422\n",
            "#93 Loss: 0.0036846317816525698\n",
            "#94 Loss: 0.0036797288339585066\n",
            "#95 Loss: 0.0036749716382473707\n",
            "#96 Loss: 0.003670360194519162\n",
            "#97 Loss: 0.0036658791359514\n",
            "#98 Loss: 0.003661523573100567\n",
            "#99 Loss: 0.003657301189377904\n",
            "#100 Loss: 0.003653197782114148\n",
            "#101 Loss: 0.0036492024082690477\n",
            "#102 Loss: 0.0036453139036893845\n",
            "#103 Loss: 0.003641535295173526\n",
            "#104 Loss: 0.003637860296294093\n",
            "#105 Loss: 0.0036342863459140062\n",
            "#106 Loss: 0.0036307896953076124\n",
            "#107 Loss: 0.003627395024523139\n",
            "#108 Loss: 0.00362408603541553\n",
            "#109 Loss: 0.0036208562087267637\n",
            "#110 Loss: 0.003617712529376149\n",
            "#111 Loss: 0.003614643355831504\n",
            "#112 Loss: 0.0036116393748670816\n",
            "#113 Loss: 0.0036087215412408113\n",
            "#114 Loss: 0.0036058619152754545\n",
            "#115 Loss: 0.0036030716728419065\n",
            "#116 Loss: 0.0036003487184643745\n",
            "#117 Loss: 0.0035976783838123083\n",
            "#118 Loss: 0.0035950681194663048\n",
            "#119 Loss: 0.003592523979023099\n",
            "#120 Loss: 0.0035900280345231295\n",
            "#121 Loss: 0.003587583778426051\n",
            "#122 Loss: 0.0035851963330060244\n",
            "#123 Loss: 0.003582856385037303\n",
            "#124 Loss: 0.003580560674890876\n",
            "#125 Loss: 0.003578306408599019\n",
            "#126 Loss: 0.003576110117137432\n",
            "#127 Loss: 0.003573950380086899\n",
            "#128 Loss: 0.0035718295257538557\n",
            "#129 Loss: 0.0035697512794286013\n",
            "#130 Loss: 0.003567706560716033\n",
            "#131 Loss: 0.0035657004918903112\n",
            "#132 Loss: 0.003563736332580447\n",
            "#133 Loss: 0.0035618010442703962\n",
            "#134 Loss: 0.0035598967224359512\n",
            "#135 Loss: 0.003558036172762513\n",
            "#136 Loss: 0.0035562021657824516\n",
            "#137 Loss: 0.003554395167157054\n",
            "#138 Loss: 0.0035526156425476074\n",
            "#139 Loss: 0.003550868481397629\n",
            "#140 Loss: 0.003549149027094245\n",
            "#141 Loss: 0.003547449829056859\n",
            "#142 Loss: 0.0035457860212773085\n",
            "#143 Loss: 0.0035441468935459852\n",
            "#144 Loss: 0.0035425268579274416\n",
            "#145 Loss: 0.003540927544236183\n",
            "#146 Loss: 0.003539356170222163\n",
            "#147 Loss: 0.003537798300385475\n",
            "#148 Loss: 0.003536270698532462\n",
            "#149 Loss: 0.003534757299348712\n",
            "#150 Loss: 0.003533268580213189\n",
            "#151 Loss: 0.003531796857714653\n",
            "#152 Loss: 0.003530343296006322\n",
            "#153 Loss: 0.0035289060324430466\n",
            "#154 Loss: 0.0035274892579764128\n",
            "#155 Loss: 0.003526088548824191\n",
            "#156 Loss: 0.003524706931784749\n",
            "#157 Loss: 0.0035233376547694206\n",
            "#158 Loss: 0.0035219835117459297\n",
            "#159 Loss: 0.0035206398461014032\n",
            "#160 Loss: 0.0035193206276744604\n",
            "#161 Loss: 0.0035180102568119764\n",
            "#162 Loss: 0.0035167101304978132\n",
            "#163 Loss: 0.003515430726110935\n",
            "#164 Loss: 0.0035141550470143557\n",
            "#165 Loss: 0.003512902185320854\n",
            "#166 Loss: 0.0035116493236273527\n",
            "#167 Loss: 0.0035104185808449984\n",
            "#168 Loss: 0.003509187139570713\n",
            "#169 Loss: 0.003507977118715644\n",
            "#170 Loss: 0.0035067733842879534\n",
            "#171 Loss: 0.0035055847838521004\n",
            "#172 Loss: 0.003504399210214615\n",
            "#173 Loss: 0.0035032257437705994\n",
            "#174 Loss: 0.0035020646173506975\n",
            "#175 Loss: 0.0035009097773581743\n",
            "#176 Loss: 0.003499762387946248\n",
            "#177 Loss: 0.0034986294340342283\n",
            "#178 Loss: 0.0034974997397512197\n",
            "#179 Loss: 0.0034963733050972223\n",
            "#180 Loss: 0.0034952592104673386\n",
            "#181 Loss: 0.0034941574558615685\n",
            "#182 Loss: 0.003493061289191246\n",
            "#183 Loss: 0.003491963492706418\n",
            "#184 Loss: 0.0034908850211650133\n",
            "#185 Loss: 0.0034897990990430117\n",
            "#186 Loss: 0.003488730639219284\n",
            "#187 Loss: 0.003487667068839073\n",
            "#188 Loss: 0.0034866060595959425\n",
            "#189 Loss: 0.0034855513367801905\n",
            "#190 Loss: 0.003484504297375679\n",
            "#191 Loss: 0.0034834647085517645\n",
            "#192 Loss: 0.0034824274480342865\n",
            "#193 Loss: 0.0034813936799764633\n",
            "#194 Loss: 0.0034803643357008696\n",
            "#195 Loss: 0.003479348262771964\n",
            "#196 Loss: 0.003478326601907611\n",
            "#197 Loss: 0.0034773184452205896\n",
            "#198 Loss: 0.0034763093572109938\n",
            "#199 Loss: 0.0034753053914755583\n",
            "#200 Loss: 0.003474302589893341\n",
            "#201 Loss: 0.0034733035136014223\n",
            "#202 Loss: 0.003472319571301341\n",
            "#203 Loss: 0.0034713323693722486\n",
            "#204 Loss: 0.0034703512210398912\n",
            "#205 Loss: 0.00346936727873981\n",
            "#206 Loss: 0.0034683949779719114\n",
            "#207 Loss: 0.003467419184744358\n",
            "#208 Loss: 0.003466449910774827\n",
            "#209 Loss: 0.0034654822666198015\n",
            "#210 Loss: 0.0034645230043679476\n",
            "#211 Loss: 0.0034635590855032206\n",
            "#212 Loss: 0.003462600288912654\n",
            "#213 Loss: 0.003461647778749466\n",
            "#214 Loss: 0.0034606948029249907\n",
            "#215 Loss: 0.0034597497433423996\n",
            "#216 Loss: 0.0034588004928082228\n",
            "#217 Loss: 0.003457858460023999\n",
            "#218 Loss: 0.0034569157287478447\n",
            "#219 Loss: 0.003455977886915207\n",
            "#220 Loss: 0.0034550342243164778\n",
            "#221 Loss: 0.003454099642112851\n",
            "#222 Loss: 0.003453172044828534\n",
            "#223 Loss: 0.003452237695455551\n",
            "#224 Loss: 0.0034513112623244524\n",
            "#225 Loss: 0.003450380638241768\n",
            "#226 Loss: 0.0034494567662477493\n",
            "#227 Loss: 0.003448534058406949\n",
            "#228 Loss: 0.0034476127475500107\n",
            "#229 Loss: 0.003446693532168865\n",
            "#230 Loss: 0.0034457768779248\n",
            "#231 Loss: 0.0034448576625436544\n",
            "#232 Loss: 0.003443947061896324\n",
            "#233 Loss: 0.0034430299419909716\n",
            "#234 Loss: 0.003442116780206561\n",
            "#235 Loss: 0.003441206179559231\n",
            "#236 Loss: 0.0034402962774038315\n",
            "#237 Loss: 0.003439391730353236\n",
            "#238 Loss: 0.003438479034230113\n",
            "#239 Loss: 0.0034375793766230345\n",
            "#240 Loss: 0.0034366741310805082\n",
            "#241 Loss: 0.003435766324400902\n",
            "#242 Loss: 0.0034348666667938232\n",
            "#243 Loss: 0.0034339698031544685\n",
            "#244 Loss: 0.003433063393458724\n",
            "#245 Loss: 0.0034321665298193693\n",
            "#246 Loss: 0.0034312692005187273\n",
            "#247 Loss: 0.003430371405556798\n",
            "#248 Loss: 0.0034294696524739265\n",
            "#249 Loss: 0.0034285758156329393\n",
            "#250 Loss: 0.0034276817459613085\n",
            "#251 Loss: 0.0034267876762896776\n",
            "#252 Loss: 0.0034258931409567595\n",
            "#253 Loss: 0.0034250004682689905\n",
            "#254 Loss: 0.003424108726903796\n",
            "#255 Loss: 0.0034232167527079582\n",
            "#256 Loss: 0.0034223247785121202\n",
            "#257 Loss: 0.0034214321058243513\n",
            "#258 Loss: 0.003420543624088168\n",
            "#259 Loss: 0.003419657004997134\n",
            "#260 Loss: 0.0034187675919383764\n",
            "#261 Loss: 0.00341787445358932\n",
            "#262 Loss: 0.003416985971853137\n",
            "#263 Loss: 0.0034161049406975508\n",
            "#264 Loss: 0.0034152157604694366\n",
            "#265 Loss: 0.0034143307711929083\n",
            "#266 Loss: 0.0034134432207792997\n",
            "#267 Loss: 0.0034125521779060364\n",
            "#268 Loss: 0.0034116702154278755\n",
            "#269 Loss: 0.003410790115594864\n",
            "#270 Loss: 0.0034099016338586807\n",
            "#271 Loss: 0.003409018972888589\n",
            "#272 Loss: 0.003408129094168544\n",
            "#273 Loss: 0.0034072448033839464\n",
            "#274 Loss: 0.0034063628409057856\n",
            "#275 Loss: 0.003405475988984108\n",
            "#276 Loss: 0.0034045951906591654\n",
            "#277 Loss: 0.0034037146251648664\n",
            "#278 Loss: 0.0034028266090899706\n",
            "#279 Loss: 0.0034019441809505224\n",
            "#280 Loss: 0.003401064546778798\n",
            "#281 Loss: 0.003400178626179695\n",
            "#282 Loss: 0.0033992966637015343\n",
            "#283 Loss: 0.003398410975933075\n",
            "#284 Loss: 0.0033975299447774887\n",
            "#285 Loss: 0.003396644489839673\n",
            "#286 Loss: 0.0033957629930227995\n",
            "#287 Loss: 0.0033948812633752823\n",
            "#288 Loss: 0.003394000232219696\n",
            "#289 Loss: 0.003393114311620593\n",
            "#290 Loss: 0.0033922316506505013\n",
            "#291 Loss: 0.003391352714970708\n",
            "#292 Loss: 0.003390467492863536\n",
            "#293 Loss: 0.0033895859960466623\n",
            "#294 Loss: 0.0033887072931975126\n",
            "#295 Loss: 0.00338782649487257\n",
            "#296 Loss: 0.003386944532394409\n",
            "#297 Loss: 0.003386056050658226\n",
            "#298 Loss: 0.0033851738553494215\n",
            "#299 Loss: 0.0033842928241938353\n",
            "#300 Loss: 0.003383409231901169\n",
            "#301 Loss: 0.003382525173947215\n",
            "#302 Loss: 0.003381645306944847\n",
            "#303 Loss: 0.003380757989361882\n",
            "#304 Loss: 0.003379879519343376\n",
            "#305 Loss: 0.003378993598744273\n",
            "#306 Loss: 0.0033781128004193306\n",
            "#307 Loss: 0.003377225948497653\n",
            "#308 Loss: 0.0033763416577130556\n",
            "#309 Loss: 0.0033754557371139526\n",
            "#310 Loss: 0.003374570282176137\n",
            "#311 Loss: 0.0033736873883754015\n",
            "#312 Loss: 0.0033728014677762985\n",
            "#313 Loss: 0.0033719188068062067\n",
            "#314 Loss: 0.0033710331190377474\n",
            "#315 Loss: 0.0033701490610837936\n",
            "#316 Loss: 0.0033692640718072653\n",
            "#317 Loss: 0.0033683739602565765\n",
            "#318 Loss: 0.0033674929291009903\n",
            "#319 Loss: 0.0033666088711470366\n",
            "#320 Loss: 0.003365717828273773\n",
            "#321 Loss: 0.0033648342359811068\n",
            "#322 Loss: 0.00336394808255136\n",
            "#323 Loss: 0.0033630577381700277\n",
            "#324 Loss: 0.0033621687907725573\n",
            "#325 Loss: 0.0033612847328186035\n",
            "#326 Loss: 0.0033603983465582132\n",
            "#327 Loss: 0.0033595103304833174\n",
            "#328 Loss: 0.0033586241770535707\n",
            "#329 Loss: 0.00335773266851902\n",
            "#330 Loss: 0.0033568472135812044\n",
            "#331 Loss: 0.003355959430336952\n",
            "#332 Loss: 0.0033550660591572523\n",
            "#333 Loss: 0.0033541813027113676\n",
            "#334 Loss: 0.0033532872330397367\n",
            "#335 Loss: 0.0033524015452712774\n",
            "#336 Loss: 0.0033515074755996466\n",
            "#337 Loss: 0.003350618062540889\n",
            "#338 Loss: 0.003349728649482131\n",
            "#339 Loss: 0.0033488357439637184\n",
            "#340 Loss: 0.0033479456324130297\n",
            "#341 Loss: 0.0033470543567091227\n",
            "#342 Loss: 0.0033461598213762045\n",
            "#343 Loss: 0.003345269011333585\n",
            "#344 Loss: 0.003344376804307103\n",
            "#345 Loss: 0.0033434825018048286\n",
            "#346 Loss: 0.003342590294778347\n",
            "#347 Loss: 0.00334169901907444\n",
            "#348 Loss: 0.00334080564789474\n",
            "#349 Loss: 0.003339909017086029\n",
            "#350 Loss: 0.0033390161115676165\n",
            "#351 Loss: 0.0033381215762346983\n",
            "#352 Loss: 0.003337223781272769\n",
            "#353 Loss: 0.0033363255206495523\n",
            "#354 Loss: 0.003335433080792427\n",
            "#355 Loss: 0.0033345327246934175\n",
            "#356 Loss: 0.0033336400520056486\n",
            "#357 Loss: 0.003332742489874363\n",
            "#358 Loss: 0.0033318500500172377\n",
            "#359 Loss: 0.003330955049023032\n",
            "#360 Loss: 0.0033300528302788734\n",
            "#361 Loss: 0.0033291552681475878\n",
            "#362 Loss: 0.0033282581716775894\n",
            "#363 Loss: 0.0033273601438850164\n",
            "#364 Loss: 0.0033264600206166506\n",
            "#365 Loss: 0.0033255601301789284\n",
            "#366 Loss: 0.0033246621023863554\n",
            "#367 Loss: 0.0033237661700695753\n",
            "#368 Loss: 0.0033228618558496237\n",
            "#369 Loss: 0.0033219624310731888\n",
            "#370 Loss: 0.0033210620749741793\n",
            "#371 Loss: 0.0033201586920768023\n",
            "#372 Loss: 0.0033192597329616547\n",
            "#373 Loss: 0.0033183563500642776\n",
            "#374 Loss: 0.003317452035844326\n",
            "#375 Loss: 0.003316550748422742\n",
            "#376 Loss: 0.003315648762509227\n",
            "#377 Loss: 0.003314743982627988\n",
            "#378 Loss: 0.003313835710287094\n",
            "#379 Loss: 0.0033129362855106592\n",
            "#380 Loss: 0.0033120308071374893\n",
            "#381 Loss: 0.0033111274242401123\n",
            "#382 Loss: 0.003310221014544368\n",
            "#383 Loss: 0.0033093176316469908\n",
            "#384 Loss: 0.0033084163442254066\n",
            "#385 Loss: 0.0033075064420700073\n",
            "#386 Loss: 0.0033066056203097105\n",
            "#387 Loss: 0.0033056947868317366\n",
            "#388 Loss: 0.0033047839533537626\n",
            "#389 Loss: 0.0033038733527064323\n",
            "#390 Loss: 0.0033029683399945498\n",
            "#391 Loss: 0.003302060067653656\n",
            "#392 Loss: 0.003301154123619199\n",
            "#393 Loss: 0.003300247946754098\n",
            "#394 Loss: 0.0032993359491229057\n",
            "#395 Loss: 0.003298429073765874\n",
            "#396 Loss: 0.0032975170761346817\n",
            "#397 Loss: 0.0032966050785034895\n",
            "#398 Loss: 0.0032957002986222506\n",
            "#399 Loss: 0.003294785274192691\n",
            "#400 Loss: 0.0032938725780695677\n",
            "#401 Loss: 0.00329295895062387\n",
            "#402 Loss: 0.0032920485828071833\n",
            "#403 Loss: 0.00329113588668406\n",
            "#404 Loss: 0.0032902283128350973\n",
            "#405 Loss: 0.0032893132884055376\n",
            "#406 Loss: 0.00328839966095984\n",
            "#407 Loss: 0.0032874830067157745\n",
            "#408 Loss: 0.0032865728717297316\n",
            "#409 Loss: 0.003285660408437252\n",
            "#410 Loss: 0.003284740960225463\n",
            "#411 Loss: 0.0032838291954249144\n",
            "#412 Loss: 0.003282913938164711\n",
            "#413 Loss: 0.0032819996122270823\n",
            "#414 Loss: 0.0032810773700475693\n",
            "#415 Loss: 0.0032801677007228136\n",
            "#416 Loss: 0.003279244527220726\n",
            "#417 Loss: 0.0032783292699605227\n",
            "#418 Loss: 0.0032774123828858137\n",
            "#419 Loss: 0.0032764922361820936\n",
            "#420 Loss: 0.0032755781430751085\n",
            "#421 Loss: 0.003274657065048814\n",
            "#422 Loss: 0.00327373412437737\n",
            "#423 Loss: 0.003272823989391327\n",
            "#424 Loss: 0.0032719008158892393\n",
            "#425 Loss: 0.0032709825318306684\n",
            "#426 Loss: 0.00327005865983665\n",
            "#427 Loss: 0.003269137116149068\n",
            "#428 Loss: 0.0032682158052921295\n",
            "#429 Loss: 0.0032672975212335587\n",
            "#430 Loss: 0.003266375744715333\n",
            "#431 Loss: 0.0032654523383826017\n",
            "#432 Loss: 0.003264528466388583\n",
            "#433 Loss: 0.003263606922701001\n",
            "#434 Loss: 0.0032626863103359938\n",
            "#435 Loss: 0.0032617610413581133\n",
            "#436 Loss: 0.0032608378678560257\n",
            "#437 Loss: 0.003259916789829731\n",
            "#438 Loss: 0.0032589926850050688\n",
            "#439 Loss: 0.0032580625265836716\n",
            "#440 Loss: 0.003257140750065446\n",
            "#441 Loss: 0.0032562166452407837\n",
            "#442 Loss: 0.003255292773246765\n",
            "#443 Loss: 0.00325436401180923\n",
            "#444 Loss: 0.0032534366473555565\n",
            "#445 Loss: 0.0032525069545954466\n",
            "#446 Loss: 0.0032515854109078646\n",
            "#447 Loss: 0.0032506566494703293\n",
            "#448 Loss: 0.0032497297506779432\n",
            "#449 Loss: 0.0032488007564097643\n",
            "#450 Loss: 0.003247871296480298\n",
            "#451 Loss: 0.003246941836550832\n",
            "#452 Loss: 0.003246014704927802\n",
            "#453 Loss: 0.0032450854778289795\n",
            "#454 Loss: 0.003244153456762433\n",
            "#455 Loss: 0.003243224462494254\n",
            "#456 Loss: 0.003242290811613202\n",
            "#457 Loss: 0.003241361351683736\n",
            "#458 Loss: 0.0032404297962784767\n",
            "#459 Loss: 0.003239500569179654\n",
            "#460 Loss: 0.003238574368879199\n",
            "#461 Loss: 0.0032376397866755724\n",
            "#462 Loss: 0.0032367061357945204\n",
            "#463 Loss: 0.003235774813219905\n",
            "#464 Loss: 0.0032348406966775656\n",
            "#465 Loss: 0.0032339105382561684\n",
            "#466 Loss: 0.0032329708337783813\n",
            "#467 Loss: 0.0032320423051714897\n",
            "#468 Loss: 0.0032311088871210814\n",
            "#469 Loss: 0.003230168716982007\n",
            "#470 Loss: 0.003229238325729966\n",
            "#471 Loss: 0.0032282995525747538\n",
            "#472 Loss: 0.0032273661345243454\n",
            "#473 Loss: 0.0032264310866594315\n",
            "#474 Loss: 0.003225491615012288\n",
            "#475 Loss: 0.0032245528418570757\n",
            "#476 Loss: 0.0032236233819276094\n",
            "#477 Loss: 0.0032226822804659605\n",
            "#478 Loss: 0.0032217444386333227\n",
            "#479 Loss: 0.0032208089251071215\n",
            "#480 Loss: 0.00321987085044384\n",
            "#481 Loss: 0.0032189309131354094\n",
            "#482 Loss: 0.003217996098101139\n",
            "#483 Loss: 0.0032170552294701338\n",
            "#484 Loss: 0.003216112032532692\n",
            "#485 Loss: 0.003215177683159709\n",
            "#486 Loss: 0.003214237280189991\n",
            "#487 Loss: 0.003213295480236411\n",
            "#488 Loss: 0.003212360432371497\n",
            "#489 Loss: 0.0032114125788211823\n",
            "#490 Loss: 0.003210473572835326\n",
            "#491 Loss: 0.0032095315400511026\n",
            "#492 Loss: 0.0032085899729281664\n",
            "#493 Loss: 0.0032076432835310698\n",
            "#494 Loss: 0.0032067063730210066\n",
            "#495 Loss: 0.0032057587523013353\n",
            "#496 Loss: 0.003204816021025181\n",
            "#497 Loss: 0.003203878179192543\n",
            "#498 Loss: 0.003202933119609952\n",
            "#499 Loss: 0.003201990155503154\n",
            "#500 Loss: 0.0032010439317673445\n",
            "#501 Loss: 0.0032001042272895575\n",
            "#502 Loss: 0.003199154743924737\n",
            "#503 Loss: 0.0031982101500034332\n",
            "#504 Loss: 0.003197263926267624\n",
            "#505 Loss: 0.003196321427822113\n",
            "#506 Loss: 0.003195370314642787\n",
            "#507 Loss: 0.0031944254878908396\n",
            "#508 Loss: 0.0031934836879372597\n",
            "#509 Loss: 0.003192536300048232\n",
            "#510 Loss: 0.003191589377820492\n",
            "#511 Loss: 0.003190642921254039\n",
            "#512 Loss: 0.0031896953005343676\n",
            "#513 Loss: 0.0031887434888631105\n",
            "#514 Loss: 0.0031877935398370028\n",
            "#515 Loss: 0.0031868470832705498\n",
            "#516 Loss: 0.0031859020236879587\n",
            "#517 Loss: 0.003184950677677989\n",
            "#518 Loss: 0.0031839993316680193\n",
            "#519 Loss: 0.003183051012456417\n",
            "#520 Loss: 0.0031821001321077347\n",
            "#521 Loss: 0.0031811546068638563\n",
            "#522 Loss: 0.0031802013982087374\n",
            "#523 Loss: 0.0031792514491826296\n",
            "#524 Loss: 0.0031782963778823614\n",
            "#525 Loss: 0.0031773485243320465\n",
            "#526 Loss: 0.0031763939186930656\n",
            "#527 Loss: 0.003175441175699234\n",
            "#528 Loss: 0.0031744930893182755\n",
            "#529 Loss: 0.0031735405791550875\n",
            "#530 Loss: 0.003172585740685463\n",
            "#531 Loss: 0.0031716313678771257\n",
            "#532 Loss: 0.0031706809531897306\n",
            "#533 Loss: 0.0031697265803813934\n",
            "#534 Loss: 0.0031687740702182055\n",
            "#535 Loss: 0.0031678173691034317\n",
            "#536 Loss: 0.0031668671872466803\n",
            "#537 Loss: 0.0031659062951803207\n",
            "#538 Loss: 0.0031649537850171328\n",
            "#539 Loss: 0.0031640029046684504\n",
            "#540 Loss: 0.0031630455050617456\n",
            "#541 Loss: 0.0031620885711163282\n",
            "#542 Loss: 0.0031611293088644743\n",
            "#543 Loss: 0.0031601740047335625\n",
            "#544 Loss: 0.003159214975312352\n",
            "#545 Loss: 0.0031582603696733713\n",
            "#546 Loss: 0.0031573071610182524\n",
            "#547 Loss: 0.003156342776492238\n",
            "#548 Loss: 0.0031553886365145445\n",
            "#549 Loss: 0.003154431702569127\n",
            "#550 Loss: 0.003153478028252721\n",
            "#551 Loss: 0.003152514575049281\n",
            "#552 Loss: 0.0031515590380877256\n",
            "#553 Loss: 0.003150602802634239\n",
            "#554 Loss: 0.003149639582261443\n",
            "#555 Loss: 0.0031486775260418653\n",
            "#556 Loss: 0.0031477201264351606\n",
            "#557 Loss: 0.003146765986457467\n",
            "#558 Loss: 0.0031457983423024416\n",
            "#559 Loss: 0.0031448376830667257\n",
            "#560 Loss: 0.0031438840087503195\n",
            "#561 Loss: 0.00314292311668396\n",
            "#562 Loss: 0.0031419561710208654\n",
            "#563 Loss: 0.003140997840091586\n",
            "#564 Loss: 0.0031400350853800774\n",
            "#565 Loss: 0.003139070002362132\n",
            "#566 Loss: 0.003138107480481267\n",
            "#567 Loss: 0.003137149615213275\n",
            "#568 Loss: 0.003136182203888893\n",
            "#569 Loss: 0.003135223174467683\n",
            "#570 Loss: 0.003134261118248105\n",
            "#571 Loss: 0.0031332913786172867\n",
            "#572 Loss: 0.003132331185042858\n",
            "#573 Loss: 0.0031313698273152113\n",
            "#574 Loss: 0.003130401484668255\n",
            "#575 Loss: 0.003129440126940608\n",
            "#576 Loss: 0.0031284745782613754\n",
            "#577 Loss: 0.003127509029582143\n",
            "#578 Loss: 0.003126543713733554\n",
            "#579 Loss: 0.003125581191852689\n",
            "#580 Loss: 0.003124617738649249\n",
            "#581 Loss: 0.003123647766187787\n",
            "#582 Loss: 0.0031226829160004854\n",
            "#583 Loss: 0.0031217189971357584\n",
            "#584 Loss: 0.0031207501888275146\n",
            "#585 Loss: 0.0031197809148579836\n",
            "#586 Loss: 0.0031188130378723145\n",
            "#587 Loss: 0.003117850050330162\n",
            "#588 Loss: 0.0031168817076832056\n",
            "#589 Loss: 0.0031159145291894674\n",
            "#590 Loss: 0.0031149464193731546\n",
            "#591 Loss: 0.0031139764469116926\n",
            "#592 Loss: 0.003113011596724391\n",
            "#593 Loss: 0.003112043021246791\n",
            "#594 Loss: 0.00311107374727726\n",
            "#595 Loss: 0.0031101014465093613\n",
            "#596 Loss: 0.003109137760475278\n",
            "#597 Loss: 0.003108167788013816\n",
            "#598 Loss: 0.0031071966513991356\n",
            "#599 Loss: 0.003106228308752179\n",
            "#600 Loss: 0.003105252981185913\n",
            "#601 Loss: 0.0031042825430631638\n",
            "#602 Loss: 0.0031033146660774946\n",
            "#603 Loss: 0.0031023428309708834\n",
            "#604 Loss: 0.003101373789831996\n",
            "#605 Loss: 0.0031004075426608324\n",
            "#606 Loss: 0.003099435940384865\n",
            "#607 Loss: 0.0030984561890363693\n",
            "#608 Loss: 0.003097485052421689\n",
            "#609 Loss: 0.003096511587500572\n",
            "#610 Loss: 0.003095542313531041\n",
            "#611 Loss: 0.003094574436545372\n",
            "#612 Loss: 0.0030936021357774734\n",
            "#613 Loss: 0.0030926268082112074\n",
            "#614 Loss: 0.0030916519463062286\n",
            "#615 Loss: 0.0030906798783689737\n",
            "#616 Loss: 0.0030897066462785006\n",
            "#617 Loss: 0.003088735044002533\n",
            "#618 Loss: 0.003087761579081416\n",
            "#619 Loss: 0.003086785553023219\n",
            "#620 Loss: 0.003085806965827942\n",
            "#621 Loss: 0.003084830939769745\n",
            "#622 Loss: 0.0030838586390018463\n",
            "#623 Loss: 0.003082886105403304\n",
            "#624 Loss: 0.0030819165986031294\n",
            "#625 Loss: 0.00308093405328691\n",
            "#626 Loss: 0.003079962218180299\n",
            "#627 Loss: 0.003078985260799527\n",
            "#628 Loss: 0.003078007372096181\n",
            "#629 Loss: 0.0030770364683121443\n",
            "#630 Loss: 0.003076055319979787\n",
            "#631 Loss: 0.00307508185505867\n",
            "#632 Loss: 0.0030741014052182436\n",
            "#633 Loss: 0.0030731221195310354\n",
            "#634 Loss: 0.0030721493531018496\n",
            "#635 Loss: 0.0030711693689227104\n",
            "#636 Loss: 0.0030701952055096626\n",
            "#637 Loss: 0.003069215686991811\n",
            "#638 Loss: 0.0030682373326271772\n",
            "#639 Loss: 0.0030672613065689802\n",
            "#640 Loss: 0.003066282719373703\n",
            "#641 Loss: 0.0030653055291622877\n",
            "#642 Loss: 0.003064327174797654\n",
            "#643 Loss: 0.003063346492126584\n",
            "#644 Loss: 0.0030623674392700195\n",
            "#645 Loss: 0.0030613902490586042\n",
            "#646 Loss: 0.0030604072380810976\n",
            "#647 Loss: 0.0030594319105148315\n",
            "#648 Loss: 0.0030584551859647036\n",
            "#649 Loss: 0.003057469381019473\n",
            "#650 Loss: 0.003056487999856472\n",
            "#651 Loss: 0.0030555131379514933\n",
            "#652 Loss: 0.0030545294284820557\n",
            "#653 Loss: 0.0030535527039319277\n",
            "#654 Loss: 0.003052572486922145\n",
            "#655 Loss: 0.00305158575065434\n",
            "#656 Loss: 0.003050602972507477\n",
            "#657 Loss: 0.0030496299732476473\n",
            "#658 Loss: 0.003048645332455635\n",
            "#659 Loss: 0.003047662554308772\n",
            "#660 Loss: 0.003046683268621564\n",
            "#661 Loss: 0.003045695601031184\n",
            "#662 Loss: 0.0030447181779891253\n",
            "#663 Loss: 0.0030437353998422623\n",
            "#664 Loss: 0.003042755648493767\n",
            "#665 Loss: 0.003041771473363042\n",
            "#666 Loss: 0.0030407842714339495\n",
            "#667 Loss: 0.003039799863472581\n",
            "#668 Loss: 0.003038819180801511\n",
            "#669 Loss: 0.003037837566807866\n",
            "#670 Loss: 0.0030368573497980833\n",
            "#671 Loss: 0.003035874105989933\n",
            "#672 Loss: 0.003034883411601186\n",
            "#673 Loss: 0.0030339041259139776\n",
            "#674 Loss: 0.003032919019460678\n",
            "#675 Loss: 0.0030319374054670334\n",
            "#676 Loss: 0.0030309483408927917\n",
            "#677 Loss: 0.003029964165762067\n",
            "#678 Loss: 0.003028980689123273\n",
            "#679 Loss: 0.0030279923230409622\n",
            "#680 Loss: 0.003027014434337616\n",
            "#681 Loss: 0.0030260265339165926\n",
            "#682 Loss: 0.0030250363051891327\n",
            "#683 Loss: 0.0030240537598729134\n",
            "#684 Loss: 0.003023069119080901\n",
            "#685 Loss: 0.003022082382813096\n",
            "#686 Loss: 0.0030210965778678656\n",
            "#687 Loss: 0.0030201098416000605\n",
            "#688 Loss: 0.003019120777025819\n",
            "#689 Loss: 0.0030181349720805883\n",
            "#690 Loss: 0.003017149632796645\n",
            "#691 Loss: 0.0030161652248352766\n",
            "#692 Loss: 0.0030151773244142532\n",
            "#693 Loss: 0.003014187328517437\n",
            "#694 Loss: 0.003013201057910919\n",
            "#695 Loss: 0.0030122166499495506\n",
            "#696 Loss: 0.003011225024238229\n",
            "#697 Loss: 0.003010241547599435\n",
            "#698 Loss: 0.0030092475935816765\n",
            "#699 Loss: 0.003008262487128377\n",
            "#700 Loss: 0.003007272956892848\n",
            "#701 Loss: 0.003006284823641181\n",
            "#702 Loss: 0.003005300648510456\n",
            "#703 Loss: 0.00300431065261364\n",
            "#704 Loss: 0.0030033213552087545\n",
            "#705 Loss: 0.0030023299623280764\n",
            "#706 Loss: 0.003001345554366708\n",
            "#707 Loss: 0.0030003550928086042\n",
            "#708 Loss: 0.0029993702191859484\n",
            "#709 Loss: 0.0029983764979988337\n",
            "#710 Loss: 0.0029973832424730062\n",
            "#711 Loss: 0.0029963937122374773\n",
            "#712 Loss: 0.0029954100027680397\n",
            "#713 Loss: 0.0029944179113954306\n",
            "#714 Loss: 0.0029934316407889128\n",
            "#715 Loss: 0.002992434659972787\n",
            "#716 Loss: 0.0029914490878582\n",
            "#717 Loss: 0.0029904532711952925\n",
            "#718 Loss: 0.002989468164741993\n",
            "#719 Loss: 0.0029884802643209696\n",
            "#720 Loss: 0.0029874860774725676\n",
            "#721 Loss: 0.0029864937532693148\n",
            "#722 Loss: 0.0029855098109692335\n",
            "#723 Loss: 0.002984515391290188\n",
            "#724 Loss: 0.0029835235327482224\n",
            "#725 Loss: 0.002982530975714326\n",
            "#726 Loss: 0.0029815398156642914\n",
            "#727 Loss: 0.0029805516824126244\n",
            "#728 Loss: 0.0029795535374432802\n",
            "#729 Loss: 0.002978563541546464\n",
            "#730 Loss: 0.0029775723814964294\n",
            "#731 Loss: 0.002976582385599613\n",
            "#732 Loss: 0.0029755812138319016\n",
            "#733 Loss: 0.00297459214925766\n",
            "#734 Loss: 0.002973601222038269\n",
            "#735 Loss: 0.0029726072680205107\n",
            "#736 Loss: 0.0029716200660914183\n",
            "#737 Loss: 0.0029706221539527178\n",
            "#738 Loss: 0.002969629131257534\n",
            "#739 Loss: 0.002968637505546212\n",
            "#740 Loss: 0.002967646112665534\n",
            "#741 Loss: 0.0029666495975106955\n",
            "#742 Loss: 0.0029656554106622934\n",
            "#743 Loss: 0.0029646616894751787\n",
            "#744 Loss: 0.002963671460747719\n",
            "#745 Loss: 0.002962673781439662\n",
            "#746 Loss: 0.0029616805259138346\n",
            "#747 Loss: 0.0029606858734041452\n",
            "#748 Loss: 0.0029596963431686163\n",
            "#749 Loss: 0.0029587019234895706\n",
            "#750 Loss: 0.0029577079694718122\n",
            "#751 Loss: 0.0029567114543169737\n",
            "#752 Loss: 0.002955714939162135\n",
            "#753 Loss: 0.002954725408926606\n",
            "#754 Loss: 0.002953729359433055\n",
            "#755 Loss: 0.002952736569568515\n",
            "#756 Loss: 0.0029517393559217453\n",
            "#757 Loss: 0.0029507416766136885\n",
            "#758 Loss: 0.0029497481882572174\n",
            "#759 Loss: 0.002948753535747528\n",
            "#760 Loss: 0.0029477577190846205\n",
            "#761 Loss: 0.0029467635322362185\n",
            "#762 Loss: 0.0029457693453878164\n",
            "#763 Loss: 0.0029447765555232763\n",
            "#764 Loss: 0.0029437756165862083\n",
            "#765 Loss: 0.002942783059552312\n",
            "#766 Loss: 0.0029417809564620256\n",
            "#767 Loss: 0.002940788632258773\n",
            "#768 Loss: 0.002939790254458785\n",
            "#769 Loss: 0.00293879397213459\n",
            "#770 Loss: 0.0029378000181168318\n",
            "#771 Loss: 0.0029368025716394186\n",
            "#772 Loss: 0.0029358044266700745\n",
            "#773 Loss: 0.002934807213023305\n",
            "#774 Loss: 0.0029338172171264887\n",
            "#775 Loss: 0.0029328176751732826\n",
            "#776 Loss: 0.002931823255494237\n",
            "#777 Loss: 0.002930824412032962\n",
            "#778 Loss: 0.002929826034232974\n",
            "#779 Loss: 0.002928832545876503\n",
            "#780 Loss: 0.002927834400907159\n",
            "#781 Loss: 0.002926832064986229\n",
            "#782 Loss: 0.0029258374124765396\n",
            "#783 Loss: 0.0029248397331684828\n",
            "#784 Loss: 0.0029238425195217133\n",
            "#785 Loss: 0.002922845771536231\n",
            "#786 Loss: 0.002921844832599163\n",
            "#787 Loss: 0.0029208508785814047\n",
            "#788 Loss: 0.002919855760410428\n",
            "#789 Loss: 0.0029188524931669235\n",
            "#790 Loss: 0.002917856676504016\n",
            "#791 Loss: 0.002916865050792694\n",
            "#792 Loss: 0.002915860153734684\n",
            "#793 Loss: 0.0029148636385798454\n",
            "#794 Loss: 0.0029138661921024323\n",
            "#795 Loss: 0.0029128678143024445\n",
            "#796 Loss: 0.0029118640813976526\n",
            "#797 Loss: 0.002910870360210538\n",
            "#798 Loss: 0.0029098677914589643\n",
            "#799 Loss: 0.002908870577812195\n",
            "#800 Loss: 0.0029078777879476547\n",
            "#801 Loss: 0.0029068763833492994\n",
            "#802 Loss: 0.0029058775398880243\n",
            "#803 Loss: 0.0029048779979348183\n",
            "#804 Loss: 0.002903879387304187\n",
            "#805 Loss: 0.0029028812423348427\n",
            "#806 Loss: 0.0029018830973654985\n",
            "#807 Loss: 0.0029008795972913504\n",
            "#808 Loss: 0.0028998826164752245\n",
            "#809 Loss: 0.0028988849371671677\n",
            "#810 Loss: 0.002897883066907525\n",
            "#811 Loss: 0.002896880963817239\n",
            "#812 Loss: 0.002895885379984975\n",
            "#813 Loss: 0.0028948874678462744\n",
            "#814 Loss: 0.002893883967772126\n",
            "#815 Loss: 0.0028928855899721384\n",
            "#816 Loss: 0.0028918851166963577\n",
            "#817 Loss: 0.0028908855747431517\n",
            "#818 Loss: 0.0028898834716528654\n",
            "#819 Loss: 0.0028888892848044634\n",
            "#820 Loss: 0.002887887880206108\n",
            "#821 Loss: 0.0028868892695754766\n",
            "#822 Loss: 0.002885882742702961\n",
            "#823 Loss: 0.0028848841320723295\n",
            "#824 Loss: 0.0028838820289820433\n",
            "#825 Loss: 0.002882886677980423\n",
            "#826 Loss: 0.0028818838763982058\n",
            "#827 Loss: 0.002880890155211091\n",
            "#828 Loss: 0.002879885258153081\n",
            "#829 Loss: 0.002878886414691806\n",
            "#830 Loss: 0.0028778808191418648\n",
            "#831 Loss: 0.002876879647374153\n",
            "#832 Loss: 0.0028758812695741653\n",
            "#833 Loss: 0.002874883823096752\n",
            "#834 Loss: 0.0028738814871758223\n",
            "#835 Loss: 0.002872879384085536\n",
            "#836 Loss: 0.002871876582503319\n",
            "#837 Loss: 0.0028708751779049635\n",
            "#838 Loss: 0.002869879826903343\n",
            "#839 Loss: 0.002868878887966275\n",
            "#840 Loss: 0.00286787748336792\n",
            "#841 Loss: 0.002866877242922783\n",
            "#842 Loss: 0.0028658744413405657\n",
            "#843 Loss: 0.0028648721054196358\n",
            "#844 Loss: 0.0028638679068535566\n",
            "#845 Loss: 0.002862868132069707\n",
            "#846 Loss: 0.002861872548237443\n",
            "#847 Loss: 0.002860868349671364\n",
            "#848 Loss: 0.002859865315258503\n",
            "#849 Loss: 0.002858861582353711\n",
            "#850 Loss: 0.002857864135876298\n",
            "#851 Loss: 0.0028568587731570005\n",
            "#852 Loss: 0.0028558559715747833\n",
            "#853 Loss: 0.0028548554982990026\n",
            "#854 Loss: 0.002853855723515153\n",
            "#855 Loss: 0.0028528522234410048\n",
            "#856 Loss: 0.002851850353181362\n",
            "#857 Loss: 0.0028508503455668688\n",
            "#858 Loss: 0.002849850570783019\n",
            "#859 Loss: 0.0028488468378782272\n",
            "#860 Loss: 0.0028478449676185846\n",
            "#861 Loss: 0.0028468426316976547\n",
            "#862 Loss: 0.0028458379674702883\n",
            "#863 Loss: 0.002844837261363864\n",
            "#864 Loss: 0.0028438412118703127\n",
            "#865 Loss: 0.0028428377117961645\n",
            "#866 Loss: 0.00284183188341558\n",
            "#867 Loss: 0.00284083210863173\n",
            "#868 Loss: 0.0028398267459124327\n",
            "#869 Loss: 0.0028388246428221464\n",
            "#870 Loss: 0.00283782253973186\n",
            "#871 Loss: 0.0028368241619318724\n",
            "#872 Loss: 0.002835817402228713\n",
            "#873 Loss: 0.0028348190244287252\n",
            "#874 Loss: 0.0028338159900158644\n",
            "#875 Loss: 0.002832813421264291\n",
            "#876 Loss: 0.0028318101540207863\n",
            "#877 Loss: 0.0028308082837611437\n",
            "#878 Loss: 0.002829807810485363\n",
            "#879 Loss: 0.002828804077580571\n",
            "#880 Loss: 0.002827805234119296\n",
            "#881 Loss: 0.002826803596690297\n",
            "#882 Loss: 0.0028257949743419886\n",
            "#883 Loss: 0.002824792405590415\n",
            "#884 Loss: 0.0028237944934517145\n",
            "#885 Loss: 0.0028227875009179115\n",
            "#886 Loss: 0.002821787493303418\n",
            "#887 Loss: 0.002820785855874419\n",
            "#888 Loss: 0.00281977909617126\n",
            "#889 Loss: 0.0028187830466777086\n",
            "#890 Loss: 0.0028177741914987564\n",
            "#891 Loss: 0.0028167730197310448\n",
            "#892 Loss: 0.0028157730121165514\n",
            "#893 Loss: 0.002814770443364978\n",
            "#894 Loss: 0.0028137657791376114\n",
            "#895 Loss: 0.002812763908877969\n",
            "#896 Loss: 0.0028117571491748095\n",
            "#897 Loss: 0.002810755744576454\n",
            "#898 Loss: 0.002809754339978099\n",
            "#899 Loss: 0.0028087517712265253\n",
            "#900 Loss: 0.00280774780549109\n",
            "#901 Loss: 0.002806747565045953\n",
            "#902 Loss: 0.0028057482559233904\n",
            "#903 Loss: 0.0028047412633895874\n",
            "#904 Loss: 0.0028037370648235083\n",
            "#905 Loss: 0.0028027351945638657\n",
            "#906 Loss: 0.002801733324304223\n",
            "#907 Loss: 0.0028007328510284424\n",
            "#908 Loss: 0.002799726789817214\n",
            "#909 Loss: 0.002798721892759204\n",
            "#910 Loss: 0.002797722117975354\n",
            "#911 Loss: 0.0027967169880867004\n",
            "#912 Loss: 0.002795712323859334\n",
            "#913 Loss: 0.002794713480398059\n",
            "#914 Loss: 0.0027937095146626234\n",
            "#915 Loss: 0.002792708808556199\n",
            "#916 Loss: 0.002791705308482051\n",
            "#917 Loss: 0.0027907025068998337\n",
            "#918 Loss: 0.002789699239656329\n",
            "#919 Loss: 0.0027886952739208937\n",
            "#920 Loss: 0.002787693403661251\n",
            "#921 Loss: 0.0027866882737725973\n",
            "#922 Loss: 0.0027856871020048857\n",
            "#923 Loss: 0.002784685231745243\n",
            "#924 Loss: 0.002783676842227578\n",
            "#925 Loss: 0.002782676601782441\n",
            "#926 Loss: 0.002781676361337304\n",
            "#927 Loss: 0.0027806691359728575\n",
            "#928 Loss: 0.00277966377325356\n",
            "#929 Loss: 0.002778667025268078\n",
            "#930 Loss: 0.0027776609640568495\n",
            "#931 Loss: 0.002776664448902011\n",
            "#932 Loss: 0.0027756590861827135\n",
            "#933 Loss: 0.0027746555861085653\n",
            "#934 Loss: 0.0027736497577279806\n",
            "#935 Loss: 0.0027726476546376944\n",
            "#936 Loss: 0.002771645085886121\n",
            "#937 Loss: 0.0027706425171345472\n",
            "#938 Loss: 0.002769639017060399\n",
            "#939 Loss: 0.0027686378452926874\n",
            "#940 Loss: 0.002767633879557252\n",
            "#941 Loss: 0.0027666331734508276\n",
            "#942 Loss: 0.002765627345070243\n",
            "#943 Loss: 0.0027646252419799566\n",
            "#944 Loss: 0.0027636198792606592\n",
            "#945 Loss: 0.002762622432783246\n",
            "#946 Loss: 0.002761618932709098\n",
            "#947 Loss: 0.002760615199804306\n",
            "#948 Loss: 0.0027596130967140198\n",
            "#949 Loss: 0.0027586128562688828\n",
            "#950 Loss: 0.0027576067950576544\n",
            "#951 Loss: 0.0027566011995077133\n",
            "#952 Loss: 0.0027556016575545073\n",
            "#953 Loss: 0.0027545990888029337\n",
            "#954 Loss: 0.0027535948902368546\n",
            "#955 Loss: 0.002752593019977212\n",
            "#956 Loss: 0.0027515890542417765\n",
            "#957 Loss: 0.002750591142103076\n",
            "#958 Loss: 0.0027495853137224913\n",
            "#959 Loss: 0.0027485874015837908\n",
            "#960 Loss: 0.002747578779235482\n",
            "#961 Loss: 0.00274657947011292\n",
            "#962 Loss: 0.0027455731760710478\n",
            "#963 Loss: 0.002744573401287198\n",
            "#964 Loss: 0.002743567107245326\n",
            "#965 Loss: 0.0027425687294453382\n",
            "#966 Loss: 0.00274156522937119\n",
            "#967 Loss: 0.002740564988926053\n",
            "#968 Loss: 0.0027395617216825485\n",
            "#969 Loss: 0.0027385565917938948\n",
            "#970 Loss: 0.0027375572826713324\n",
            "#971 Loss: 0.0027365554124116898\n",
            "#972 Loss: 0.0027355507481843233\n",
            "#973 Loss: 0.002734550042077899\n",
            "#974 Loss: 0.002733544446527958\n",
            "#975 Loss: 0.0027325404807925224\n",
            "#976 Loss: 0.0027315430343151093\n",
            "#977 Loss: 0.0027305379044264555\n",
            "#978 Loss: 0.002729540690779686\n",
            "#979 Loss: 0.0027285360265523195\n",
            "#980 Loss: 0.002727535320445895\n",
            "#981 Loss: 0.0027265355456620455\n",
            "#982 Loss: 0.0027255273889750242\n",
            "#983 Loss: 0.0027245264500379562\n",
            "#984 Loss: 0.0027235259767621756\n",
            "#985 Loss: 0.0027225229423493147\n",
            "#986 Loss: 0.002721521770581603\n",
            "#987 Loss: 0.002720518736168742\n",
            "#988 Loss: 0.0027195170987397432\n",
            "#989 Loss: 0.002718515694141388\n",
            "#990 Loss: 0.0027175117284059525\n",
            "#991 Loss: 0.002716516377404332\n",
            "#992 Loss: 0.0027155138086527586\n",
            "#993 Loss: 0.002714508445933461\n",
            "#994 Loss: 0.0027135105337947607\n",
            "#995 Loss: 0.0027125056367367506\n",
            "#996 Loss: 0.002711501671001315\n",
            "#997 Loss: 0.0027105023618787527\n",
            "#998 Loss: 0.0027095014229416847\n",
            "#999 Loss: 0.002708497690036893\n",
            "Predicted data based on trained weights: \n",
            "Input (scaled): \n",
            "tensor([0.5000, 1.0000])\n",
            "Output: \n",
            "tensor([0.9260])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Neural_Network. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJCqPr1rdR8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}